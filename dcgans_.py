# -*- coding: utf-8 -*-
"""DCGans_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sFCXb05XN7iufuHAzvg6gxXiMcDAIFfy
"""

!pip install datasets

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from datasets import load_dataset

# Set device to GPU if available, otherwise use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load the LSUN Bedroom dataset from Hugging Face
dataset = load_dataset("pcuenq/lsun-bedrooms", split="train")

# Define image transformations for preprocessing
transform = transforms.Compose([
    transforms.Resize(64),  # Resize images to 64x64 pixels
    transforms.CenterCrop(64),  # Crop the center region
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]
])
# Custom Dataset Wrapper for Hugging Face Dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image = self.dataset[idx]["image"]
        image = self.transform(image)
        return image

# Set batch size and create DataLoader for training
batch_size = 128
dataloader = DataLoader(CustomDataset(dataset, transform), batch_size=batch_size, shuffle=True)

# Hyperparameters
nz = 100  # Size of latent vector (random noise input)
ngf = 64  # Number of feature maps in Generator
ndf = 64  # Number of feature maps in Discriminator
nc = 3    # Number of image color channels (RGB)
epochs = 15  # Number of training epochs
lr = 0.0002  # Learning rate
beta1 = 0.5  # Beta1 hyperparameter for Adam optimizer

# Define the Generator Model (Corrected)
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            # Input: nz x 1 x 1 -> Output: 1024 x 4 x 4
            nn.ConvTranspose2d(nz, 1024, 4, 1, 0, bias=False),
            nn.BatchNorm2d(1024),
            nn.ReLU(True),

            # Output: 512 x 8 x 8
            nn.ConvTranspose2d(1024, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),

            # Output: 256 x 16 x 16
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),

            # Output: 128 x 32 x 32
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),

            # Output: 3 x 64 x 64 (Final image)
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

# Define the Discriminator Model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            # Input: 3 x 64 x 64 -> Output: 128 x 32 x 32
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            # Output: 256 x 16 x 16
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            # Output: 512 x 8 x 8
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),

            # Output: 1024 x 4 x 4
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),

            # Output: 1 (Real or Fake Probability)
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Initialize models and move to device
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Function to initialize model weights
def weights_init(m):
    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
        nn.init.normal_(m.weight.data, 0.0, 0.02)

# Apply weight initialization
generator.apply(weights_init)
discriminator.apply(weights_init)

# Loss function and optimizers
criterion = nn.BCELoss()
optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

# Training Loop
fixed_noise = torch.randn(64, nz, 1, 1, device=device)  # Fixed noise for visualization

print("Starting Training...")

for epoch in range(epochs):
    for i, data in enumerate(dataloader):
        real_images = data.to(device)
        batch_size = real_images.size(0)


        # Create real and fake labels with correct shape
        real_labels = torch.ones(batch_size, device=device)
        fake_labels = torch.zeros(batch_size, device=device)


        # Train Discriminator
        optimizerD.zero_grad()
        output_real = discriminator(real_images).view(-1)
        loss_real = criterion(output_real, real_labels)

        noise = torch.randn(batch_size, nz, 1, 1, device=device)
        fake_images = generator(noise)
        output_fake = discriminator(fake_images.detach()).view(-1)
        loss_fake = criterion(output_fake, fake_labels)

        lossD = loss_real + loss_fake
        lossD.backward()
        optimizerD.step()

        # Train Generator
        optimizerG.zero_grad()
        output = discriminator(fake_images).view(-1)
        lossG = criterion(output, real_labels)
        lossG.backward()
        optimizerG.step()

        # Print training progress
        if i % 100 == 0:
            print(f"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} Loss D: {lossD:.4f}, Loss G: {lossG:.4f}")

    # Save and visualize generated images
    with torch.no_grad():
        fake_images = generator(fixed_noise).detach().cpu()
    plt.figure(figsize=(8, 8))
    plt.axis("off")
    plt.imshow(vutils.make_grid(fake_images, padding=2, normalize=True).permute(1, 2, 0))
    plt.show()

# Save trained models
torch.save(generator.state_dict(), "generator.pth")
torch.save(discriminator.state_dict(), "discriminator.pth")

print("Training Complete. Models Saved.")

import numpy as np

# Get a batch of real images
real_batch = next(iter(dataloader))
real_images = real_batch[:8].to(device)  # Take first 8 images

# Generate fake images using the same real images as reference
with torch.no_grad():
    noise_vectors = torch.randn(real_images.shape[0], nz, 1, 1, device=device)  # Random noise
    fake_images = generator(noise_vectors).detach().cpu()  # Generate fake images

# Denormalize images from range [-1, 1] to [0, 1]
def denormalize(img):
    return (img * 0.5) + 0.5  # Convert back to [0,1] range

# Convert images to numpy format
real_images = real_images.cpu().numpy()
fake_images = fake_images.numpy()

# Create a figure to display real and fake images side by side
fig, axes = plt.subplots(2, 8, figsize=(16, 4))

for i in range(8):
    # Display real images (top row)
    axes[0, i].imshow(np.transpose(denormalize(real_images[i]), (1, 2, 0)))
    axes[0, i].axis("off")
    axes[0, i].set_title("Real")

    # Display fake images (bottom row)
    axes[1, i].imshow(np.transpose(denormalize(fake_images[i]), (1, 2, 0)))
    axes[1, i].axis("off")
    axes[1, i].set_title("Fake")

plt.suptitle("Real vs. Fake Images (Same Reference)", fontsize=14)
plt.show()

from google.colab import auth
auth.authenticate_user()